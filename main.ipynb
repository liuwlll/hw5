{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 指定文件路径\n",
    "def get_texts(folder_path,data):\n",
    "    texts=[]\n",
    "    for guid in data['guid']:\n",
    "        file = folder_path + str(guid)+\".txt\"\n",
    "        try:\n",
    "            with open(file, \"r\",encoding=\"GB18030\") as f:\n",
    "                text = f.read()\n",
    "                texts.append(text)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    return texts\n",
    "\n",
    "# 文本预处理函数\n",
    "def text_tokenizer(texts):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(texts)  # 文本训练Tokenizer\n",
    "    sequences = tokenizer.texts_to_sequences(texts)  # 转换为整数序列\n",
    "    padded_sequences = pad_sequences(sequences, maxlen = 200)  # 填充序列统一长度\n",
    "    return padded_sequences, tokenizer\n",
    "\n",
    "folder_path = \"dataset/data/\"\n",
    "train_path = \"dataset/train.txt\"\n",
    "train_data = pd.read_csv(train_path,sep=\",\")\n",
    "tags = {\"positive\": 0, \"negative\": 1,\"neutral\":2}\n",
    "replaced_data = train_data.replace({\"tag\": tags})\n",
    "labels = list(replaced_data['tag'])\n",
    "\n",
    "texts = get_texts(folder_path,replaced_data)\n",
    "# 调用文本预处理函数\n",
    "processed_texts, tokenizer = text_tokenizer(texts)\n",
    "#print(processed_texts)\n",
    "\n",
    "\n",
    "def get_images(folder_path ,data):\n",
    "    image_paths = []\n",
    "    for guid in data['guid']:\n",
    "        image_path = folder_path + str(guid) + \".jpg\"\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            height,width,channels = image.shape\n",
    "            image_paths.append(image_path)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return image_paths\n",
    "\n",
    "# 图像数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 图片缩放到vgg统一大小\n",
    "    transforms.ToTensor(),  # 将图片转换为tensor\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "image_paths = get_images(folder_path,replaced_data)\n",
    "#print(image_paths)\n",
    "\n",
    "\n",
    "# 准备数据集和数据加载器\n",
    "class FusionModelDataset(Dataset):\n",
    "    def __init__(self, image_paths, text_sequences, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.text_sequences = text_sequences\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        text_sequence = self.text_sequences[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, text_sequence, label\n",
    "\n",
    "\n",
    "# 定义图像特征提取器#############################################################\n",
    "class ImageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.vgg = vgg16(pretrained=True).features\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.fc = nn.Linear(512 * 7 * 7, 4096)  # 调整全连接层的输出维度\n",
    "        #self.dropout = nn.Dropout(0.5)  # 添加Dropout层进行正则化//\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.vgg(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #x = self.dropout(x)  # 在全连接层前应用Dropout层\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 定义文本特征提取器###################################################################\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(TextModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        x = h_n.squeeze(0)\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "# 定义多模态融合模型#######################################################################\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, classes, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.image_extractor = ImageModel()\n",
    "        self.text_extractor = TextModel(vocab_size, embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(4096 + hidden_dim, classes)\n",
    "        \n",
    "    def forward(self, image, text):\n",
    "        image_features = self.image_extractor(image)\n",
    "        text_features = self.text_extractor(text)\n",
    "        features = torch.cat((image_features, text_features), dim=1)\n",
    "        output = self.fc(features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "classes = 3\n",
    "vocab_size = len(tokenizer.word_index) + 1  # tokenizer从1开始索引\n",
    "embedding_dim = 100\n",
    "hidden_dim = 100\n",
    "batch_size = 64 \n",
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(0.8 * len(labels))\n",
    "train_image_paths = image_paths[:train_size]\n",
    "train_text_sequences = processed_texts[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "valid_image_paths = image_paths[train_size:]\n",
    "valid_text_sequences = processed_texts[train_size:]\n",
    "valid_labels = labels[train_size:]\n",
    "\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "train_dataset = FusionModelDataset(train_image_paths, train_text_sequences, train_labels, transform)\n",
    "valid_dataset = FusionModelDataset(valid_image_paths, valid_text_sequences, valid_labels, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = FusionModel(classes, vocab_size, embedding_dim, hidden_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_model_path = 'best_model.pt'  # 最佳模型的保存路径\n",
    "\n",
    "print(\"多模态模型:\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}训练中……')\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for images, texts, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # 更新学习率\n",
    "        #scheduler.step()\n",
    "\n",
    "        outputs = model(images, texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, texts, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            texts = texts.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images, texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            valid_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    valid_loss /= len(valid_dataset)\n",
    "    accuracy = correct / len(valid_dataset)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取test文件并生成预测文件\n",
    "test_path = \"dataset/test_without_label.txt\"\n",
    "test_data = pd.read_csv(test_path,sep=\",\")\n",
    "test_data['tag'] = 0\n",
    "test_labels = np.array(test_data['tag'])\n",
    "test_image_paths = get_images(folder_path,test_data)\n",
    "test_texts = get_texts(folder_path,test_data)\n",
    "processed_test_texts,t = text_tokenizer(test_texts)\n",
    "\n",
    "test_dataset = FusionModelDataset(test_image_paths, processed_test_texts, test_labels, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#print(test_loader.dataset)\n",
    "\n",
    "# 加载最佳模型的参数\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, texts, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        texts = texts.to(device)\n",
    "        \n",
    "        outputs = model(images, texts)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_labels.extend(predicted.tolist())\n",
    "\n",
    "# 将预测结果写入测试集文件\n",
    "test_data['tag'] = [list(tags.keys())[label] for label in predicted_labels[:len(test_data)]]\n",
    "test_data.to_csv(\"predict1.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 创建图像数据集和加载器\n",
    "image_dataset = FusionModelDataset(valid_image_paths, valid_text_sequences, valid_labels, transform)\n",
    "image_loader = DataLoader(image_dataset, batch_size=batch_size)\n",
    "\n",
    "# 创建文本数据集和加载器\n",
    "text_dataset = FusionModelDataset(valid_image_paths, valid_text_sequences, valid_labels, transform)\n",
    "text_loader = DataLoader(text_dataset, batch_size=batch_size)\n",
    "\n",
    "# 创建只包含图像特征提取器的模型\n",
    "image_model = ImageModel()\n",
    "image_model.to(device)\n",
    "\n",
    "# 创建只包含文本特征提取器的模型\n",
    "text_model = TextModel(vocab_size, embedding_dim, hidden_dim)\n",
    "text_model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和验证图像数据模型\n",
    "image_optimizer = optim.Adam(image_model.parameters(), lr=lr)\n",
    "#image_scheduler = torch.optim.lr_scheduler.StepLR(image_optimizer, step_size=2, gamma=0.1)\n",
    "print(\"图像数据模型:\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}训练中……')\n",
    "    image_model.train()\n",
    "    image_train_loss = 0.0\n",
    "\n",
    "    for images, _, labels in image_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        image_optimizer.zero_grad()\n",
    "\n",
    "        outputs = image_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        image_optimizer.step()\n",
    "\n",
    "        image_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    image_train_loss /= len(image_dataset)\n",
    "\n",
    "    image_model.eval()\n",
    "    image_valid_loss = 0.0\n",
    "    image_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _, labels in image_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = image_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            image_valid_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            image_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    image_valid_loss /= len(image_dataset)\n",
    "    image_accuracy = image_correct / len(image_dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Image Train Loss: {image_train_loss:.4f}, Image Valid Loss: {image_valid_loss:.4f}, Image Valid Accuracy: {image_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和验证文本数据模型\n",
    "text_optimizer = optim.Adam(text_model.parameters(), lr=lr)\n",
    "#text_scheduler = torch.optim.lr_scheduler.StepLR(text_optimizer, step_size=2, gamma=0.1)\n",
    "print(\"文本数据模型:\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}训练中……')\n",
    "    text_model.train()\n",
    "    text_train_loss = 0.0\n",
    "\n",
    "    for _, texts, labels in text_loader:\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        text_optimizer.zero_grad()\n",
    "\n",
    "        outputs = text_model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        text_optimizer.step()\n",
    "\n",
    "        text_train_loss += loss.item() * texts.size(0)\n",
    "\n",
    "    text_train_loss /= len(text_dataset)\n",
    "\n",
    "    text_model.eval()\n",
    "    text_valid_loss = 0.0\n",
    "    text_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, texts, labels in text_loader:\n",
    "            texts = texts.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = text_model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            text_valid_loss += loss.item() * texts.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            text_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    text_valid_loss /= len(text_dataset)\n",
    "    text_accuracy = text_correct / len(text_dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Text Train Loss: {text_train_loss:.4f}, Text Valid Loss: {text_valid_loss:.4f}, Text Valid Accuracy: {text_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
